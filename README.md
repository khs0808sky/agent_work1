# agent_work1

## 📅 목차

- [2025-08-19](#2025-08-19)
- [2025-08-20](#2025-08-20)

<br><br><br>

---

## **2025-08-19**

---

### 1) GPT API 시작하기

* **API란?**
  응용 프로그램에서 GPT 모델을 불러와서 질문 → 응답을 자동으로 처리할 수 있도록 해주는 인터페이스.
* **시작 절차**:

  1. **API 키 발급**:

     * [OpenAI 계정](https://platform.openai.com/)에서 로그인 후 → 개인용 API 키 생성.
     * 이 키는 비밀번호처럼 중요한 정보이므로 노출되면 안 됨.
  2. **환경 설정**:

     * Python 예시:

       ```python
       from openai import OpenAI
       client = OpenAI(api_key="YOUR_API_KEY")

       response = client.chat.completions.create(
           model="gpt-4o-mini",
           messages=[{"role": "user", "content": "안녕하세요 GPT"}]
       )

       print(response.choices[0].message.content)
       ```
     * `model`에는 사용할 모델 이름 지정. (`gpt-4o`, `gpt-4o-mini`, `gpt-3.5-turbo` 등)
  3. **질문 & 답변 구조**:

     * `messages` 필드 안에 role과 content로 대화 맥락 전달.

       * `system`: 모델에게 역할/성격 지시.
       * `user`: 사용자 입력.
       * `assistant`: 모델의 응답.
* **활용 예시**:

  * 챗봇, 문서 요약기, 번역기, 코드 보조 도구 등.

---

### 2) OpenAI의 API 키로 질문하고 답변받기

* **API 키 사용 원리**:

  * OpenAI 서버로 요청을 보낼 때 인증 토큰처럼 사용됨.
  * 올바른 키가 있어야 모델이 응답을 반환.
* **중요 포인트**:

  * 키는 `.env` 같은 환경 변수에 저장 → 코드에 직접 노출하지 않는 게 안전.
  * 예시 (환경 변수 활용):

    ```python
    import os
    from openai import OpenAI

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    ```
* **응답 구조**:

  * JSON 형식으로 반환되며, `response.choices[0].message.content` 부분이 실제 답변.
  * 응답에는 토큰 사용량(`usage`)도 포함됨 → 비용 계산 가능.

---

### 3) Few-Shot Learning

* **정의**:
  모델이 \*\*적은 수의 예제(샘플)\*\*만 보고도 새로운 문제를 풀 수 있도록 하는 학습 방식.
  (반대: Zero-Shot → 예제 없이 해결, Many-Shot → 많은 예제 제공)
* **원리**:

  * GPT 같은 대규모 언어 모델은 사전 학습 시 이미 일반적인 패턴을 습득.
  * Prompt 안에 몇 개의 예시를 제공하면, 모델은 그 형식을 일반화해 새로운 입력에 적용.
* **예시**:

  ```text
  Q: 2+3은?
  A: 5
  Q: 4+7은?
  A: 11
  Q: 9+8은?
  A:
  ```

  → 모델이 "A: 17"로 답하도록 유도.
* **장점**:

  * 별도 학습(파인튜닝) 없이 원하는 태스크에 빠르게 적응.
  * 소량의 데이터로도 특정 포맷/스타일을 학습.
* **단점**:

  * Prompt 길이에 제약 있음(예시 많이 넣기 어려움).
  * 예제 선택에 따라 성능이 크게 달라짐.

---

📅[목차로 돌아가기](#-목차)

---

## **2025-08-20**

---

### 1) 문서·논문(PDF) 요약 AI 설계

* **기본 흐름**

  1. 파일 업로드 → 2) 텍스트 추출/청크 분할 → 3) 요약 프롬프트 실행 → 4) 품질 점검(팩트/출처) → 5) 최종 요약본 출력
     *OpenAI는 파일 업로드와 문서 검색을 위한 **Files / File Search**를 제공하며, 업로드한 문서를 자동으로 분할·색인해 RAG에 활용할 수 있음.*

* **직접 요약 vs. RAG 요약**

  * *직접 요약*: 긴 문서를 **Map–Reduce / Refine** 패턴으로 나눠 순차 요약 → 종합.
  * *RAG 요약*: 질문/요약 지시에 맞춰 **관련 청크만 검색**해 요약(길이/비용↓, 정확도↑).
    *파일을 모델에 바로 전달하거나, File Search로 검색 후 응답에 인용을 붙이는 방식 권장.*

* **프롬프트 팁**

  * 형식 고정: “한줄 요약 → 핵심 5개 불릿 → 한계/가정 → 참고문구(페이지·섹션)”.
  * 정확성: “원문 문장 재작성 금지, 오역 가능성 지점 표시, 수치엔 단위 포함” 등 규칙 명시.
  * 길이 제어: *문단·페이지당 토큰 한도* 지정, 최종 요약 길이(예: 500자) 고정.

* **스캔 PDF 주의**

  * 이미지 기반이면 **OCR 전처리** 후 요약(텍스트 추출 실패 방지). 표/수식은 별도 추출 규칙을 두어 요약에 포함.

* **운영 팁**

  * **품질 점검**: 샘플 정답 대비 자동 채점(사실/범주) 규칙, 인용 검증.
  * **비용·지연 최적화**: 파일 단위 캐시, 청크 길이/개수 튜닝, *요약 → 상세 질의 2단계*로 분리.
---

### 2) 음성 ↔ 한·영 텍스트 변환(ASR & TTS)

* **ASR(음성 → 텍스트)**

  * OpenAI **Speech-to-Text**(예: Whisper 계열, GPT-4o Transcribe 등)로 한국어·영어 음성을 전사하고, 필요하면 **자동 번역**을 추가. 실시간 전사도 Realtime API로 가능.
  * 핵심 옵션/주의: 언어 강제, 타임스탬프, 화자 구분(별도 처리), 잡음 제거·샘플링레이트 통일.

* **번역(텍스트 ↔ 한·영)**

  * 전사 결과를 모델에 전달해 번역. *역할 규칙*을 두고 “용어집”, “존댓말/반말”, “고유명사 보존” 지시.

* **TTS(텍스트 → 음성)**

  * **TTS 모델**로 한국어/영어 음성 합성, 품질 우선 시 *고품질 프로파일* 사용(예: tts-1-hd). 실시간 대화형이면 Realtime API 활용.

* **파이프라인 예시**

  1. **ASR**: 음성 파일 업로드 → 전사(JSON + 타임스탬프). ([OpenAI Platform][6])
  2. **정제**: 불용어/중복 제거, 구두점 복원, 도메인 용어 교정.
  3. **번역(선택)**: 지침(스타일/용어집)과 함께 번역.
  4. **TTS(선택)**: 번역문/원문을 음성으로 합성(속도/톤/목소리 선택). ([OpenAI Platform][5])

* **평가 지표**

  * 전사: **WER**(Word Error Rate)
  * 번역: **BLEU / COMET**
  * 합성: **MOS**(Mean Opinion Score) 주관평가 + 발음/억양 체크리스트

* **운영 팁**

  * **프롬프트 사전/용어집**: 고유명사·전문용어 정확도 향상.
  * **길이 제한·비용 관리**: 장시간 오디오는 분할 업로드, 긴 전사 텍스트는 요약 후 저장. ([OpenAI Platform][3])
  * **보안**: 키는 환경변수 보관, 민감 음성은 익명화/부분 마스킹 처리. ([OpenAI Platform][7])

---

### 3) 함께 쓰면 좋은 구성(요약 + 음성)

* 회의/강의 녹음 → **실시간 전사** → **요약/액션 아이템** → **한국어·영어 버전 동시 출력** → **TTS로 오디오 브리핑 생성**.
  *공식 튜토리얼(회의록)과 실시간 가이드가 구현 실마리를 제공.* ([OpenAI Platform][8])

---

📅[목차로 돌아가기](#-목차)

---

